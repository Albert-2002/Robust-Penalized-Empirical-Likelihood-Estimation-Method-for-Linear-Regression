{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.optimize import minimize\n",
    "np.set_printoptions(precision=8, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/91959/Desktop/CODE'\n",
    "                '/Robust-Penalized-Empirical-Likelihood-Estimation-Method-for-Linear-Regression/Data/Alcohol.csv')\n",
    "\n",
    "# Independent variables (features) - all columns except the first (Alcohol) and last (ln (Sol)exp)\n",
    "X = data.iloc[:, 1:-1].values  # Exclude the first column (Alcohol) and the last column (ln (Sol)exp)\n",
    "# Dependent variable (target) - last column (ln (Sol)exp)\n",
    "y = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Parameter Estimation\n",
    "## M-Estimation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Tukey's Biweight Loss Function\n",
    "def tukey_biweight_loss(residuals, c=4.685):\n",
    "    \"\"\"\n",
    "    Tukey's Biweight loss function.\n",
    "    c: Tuning constant (default is 4.685 for 95% efficiency under normality).\n",
    "    \"\"\"\n",
    "    t = np.abs(residuals) / c\n",
    "    loss = np.where(t < 1, (c**2 / 6) * (1 - (1 - t**2)**3), c**2 / 6)\n",
    "    return loss\n",
    "\n",
    "# Define the Objective Function for M-Estimation\n",
    "def m_estimation_objective(beta, X, y, c=4.685):\n",
    "    \"\"\"\n",
    "    Objective function for M-Estimation using Tukey's Biweight loss.\n",
    "    \"\"\"\n",
    "    residuals = y - np.dot(X, beta)  # Residuals\n",
    "    loss = tukey_biweight_loss(residuals, c)  # Tukey's Biweight loss\n",
    "    return np.sum(loss)  # Sum of losses\n",
    "\n",
    "# Set up k-fold cross-validation\n",
    "k = 5  # Number of folds\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=46)\n",
    "\n",
    "# Lists to store results for M-Estimation\n",
    "m_est_cv_betas = []\n",
    "m_est_cv_r2_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X), 1):\n",
    "    # Split data for this fold\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Add bias term to training data\n",
    "    X_train_bias = np.column_stack((np.ones(X_train.shape[0]), X_train))\n",
    "\n",
    "    # Initial guess for beta (start with OLS estimates)\n",
    "    XT = X_train_bias.T\n",
    "    XT_X = np.dot(XT, X_train_bias)\n",
    "    XT_X_inv = np.linalg.inv(XT_X)\n",
    "    XT_y = np.dot(XT, y_train)\n",
    "    beta_initial = np.dot(XT_X_inv, XT_y)\n",
    "\n",
    "    # Optimize the M-Estimation objective function\n",
    "    result = minimize(m_estimation_objective, beta_initial, args=(X_train_bias, y_train), method='BFGS')\n",
    "\n",
    "    # Extract the M-Estimation coefficients\n",
    "    beta_m_est = result.x\n",
    "\n",
    "    # Add bias term to test data\n",
    "    X_test_bias = np.column_stack((np.ones(X_test.shape[0]), X_test))\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = np.dot(X_test_bias, beta_m_est)\n",
    "\n",
    "    # Calculate R-squared\n",
    "    y_test_mean = np.mean(y_test)\n",
    "    SS_res = np.sum((y_test - y_pred) ** 2)\n",
    "    SS_tot = np.sum((y_test - y_test_mean) ** 2)\n",
    "    r2 = 1 - (SS_res / SS_tot)\n",
    "\n",
    "    # Store results\n",
    "    m_est_cv_betas.append(beta_m_est)\n",
    "    m_est_cv_r2_scores.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Results [M-Estimation with Tukey's Biweight]:\n",
      "Mean R-squared: 0.9353 (±0.0605)\n",
      "\n",
      "Mean Beta Coefficients:\n",
      "Intercept: 28.5005 (±19.9594)\n",
      "SAG: -0.0051 (±0.0195)\n",
      "V: -0.0137 (±0.0208)\n",
      "Log P: -2.6200 (±0.5230)\n",
      "P: 26.9565 (±17.4149)\n",
      "RM: -1.1780 (±1.3020)\n",
      "Mass: -3.0980 (±2.5931)\n"
     ]
    }
   ],
   "source": [
    "# Calculate overall mean and standard deviation of results\n",
    "m_est_mean_beta = np.mean(m_est_cv_betas, axis=0)\n",
    "m_est_std_beta = np.std(m_est_cv_betas, axis=0)\n",
    "m_est_mean_r2 = np.mean(m_est_cv_r2_scores)\n",
    "m_est_std_r2 = np.std(m_est_cv_r2_scores)\n",
    "\n",
    "print(\"\\nOverall Results [M-Estimation with Tukey's Biweight]:\")\n",
    "print(f\"Mean R-squared: {m_est_mean_r2:.4f} (±{m_est_std_r2:.4f})\")\n",
    "print(\"\\nMean Beta Coefficients:\")\n",
    "feature_names = ['Intercept'] + list(data.columns[1:-1])\n",
    "for name, beta_mean, beta_std in zip(feature_names, m_est_mean_beta, m_est_std_beta):\n",
    "    print(f\"{name}: {beta_mean:.4f} (±{beta_std:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MM-Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Tukey's Biweight Loss Function\n",
    "def tukey_biweight_loss(residuals, c=4.685):\n",
    "    \"\"\"\n",
    "    Tukey's Biweight loss function.\n",
    "    c: Tuning constant (default is 4.685 for 95% efficiency under normality).\n",
    "    \"\"\"\n",
    "    t = np.abs(residuals) / c\n",
    "    loss = np.where(t < 1, (c**2 / 6) * (1 - (1 - t**2)**3), c**2 / 6)\n",
    "    return loss\n",
    "\n",
    "# Define the S-Estimation Objective Function\n",
    "def s_estimation_objective(sigma, residuals, c=4.685):\n",
    "    \"\"\"\n",
    "    Objective function for S-Estimation using Tukey's Biweight loss.\n",
    "    \"\"\"\n",
    "    t = np.abs(residuals) / sigma\n",
    "    loss = np.where(t < 1, (c**2 / 6) * (1 - (1 - t**2)**3), c**2 / 6)\n",
    "    return np.sum(loss) - (len(residuals) / 2)  # S-Estimation condition\n",
    "\n",
    "# Define the M-Estimation Objective Function\n",
    "def m_estimation_objective(beta, X, y, sigma, c=4.685):\n",
    "    \"\"\"\n",
    "    Objective function for M-Estimation using Tukey's Biweight loss.\n",
    "    \"\"\"\n",
    "    residuals = y - np.dot(X, beta)  # Residuals\n",
    "    loss = tukey_biweight_loss(residuals / sigma, c)  # Tukey's Biweight loss\n",
    "    return np.sum(loss)  # Sum of losses\n",
    "\n",
    "# Set up k-fold cross-validation\n",
    "k = 5  # Number of folds\n",
    "kf2 = KFold(n_splits=k, shuffle=True, random_state=46)\n",
    "\n",
    "# Lists to store results for MM-Estimation\n",
    "mm_est_cv_betas = []\n",
    "mm_est_cv_r2_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(kf2.split(X), 1):\n",
    "    # Split data for this fold\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Add bias term to training data\n",
    "    X_train_bias = np.column_stack((np.ones(X_train.shape[0]), X_train))\n",
    "\n",
    "    # Step 7: S-Estimation - Estimate the scale parameter sigma\n",
    "    # Initial guess for sigma (use MAD as a robust initial estimate)\n",
    "    residuals_initial = y_train - np.dot(X_train_bias, np.linalg.lstsq(X_train_bias, y_train, rcond=None)[0])\n",
    "    sigma_initial = np.median(np.abs(residuals_initial)) / 0.6745  # MAD estimate\n",
    "\n",
    "    # Optimize the S-Estimation objective function\n",
    "    result_s = minimize(s_estimation_objective, sigma_initial, args=(residuals_initial), method='BFGS')\n",
    "    sigma_est = result_s.x[0]  # Estimated scale parameter\n",
    "\n",
    "    # Step 8: M-Estimation - Estimate the regression coefficients\n",
    "    # Initial guess for beta (start with OLS estimates)\n",
    "    XT = X_train_bias.T\n",
    "    XT_X = np.dot(XT, X_train_bias)\n",
    "    XT_X_inv = np.linalg.inv(XT_X)\n",
    "    XT_y = np.dot(XT, y_train)\n",
    "    beta_initial = np.dot(XT_X_inv, XT_y)\n",
    "\n",
    "    # Optimize the M-Estimation objective function\n",
    "    result_m = minimize(m_estimation_objective, beta_initial, args=(X_train_bias, y_train, sigma_est), method='BFGS')\n",
    "    beta_mm_est = result_m.x  # MM-Estimation coefficients\n",
    "\n",
    "    # Add bias term to test data\n",
    "    X_test_bias = np.column_stack((np.ones(X_test.shape[0]), X_test))\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = np.dot(X_test_bias, beta_mm_est)\n",
    "\n",
    "    # Calculate R-squared\n",
    "    y_test_mean = np.mean(y_test)\n",
    "    SS_res = np.sum((y_test - y_pred) ** 2)\n",
    "    SS_tot = np.sum((y_test - y_test_mean) ** 2)\n",
    "    r2 = 1 - (SS_res / SS_tot)\n",
    "\n",
    "    # Store results\n",
    "    mm_est_cv_betas.append(beta_mm_est)\n",
    "    mm_est_cv_r2_scores.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Results [MM-Estimation with Tukey's Biweight]:\n",
      "Mean R-squared: 0.9355 (±0.0598)\n",
      "\n",
      "Mean Beta Coefficients:\n",
      "Intercept: 28.5371 (±19.9718)\n",
      "SAG: -0.0062 (±0.0195)\n",
      "V: -0.0129 (±0.0203)\n",
      "Log P: -2.6110 (±0.5255)\n",
      "P: 26.8751 (±17.4076)\n",
      "RM: -1.1528 (±1.3062)\n",
      "Mass: -3.0969 (±2.5930)\n"
     ]
    }
   ],
   "source": [
    "# Calculate overall mean and standard deviation of results\n",
    "mm_est_mean_beta = np.mean(mm_est_cv_betas, axis=0)\n",
    "mm_est_std_beta = np.std(mm_est_cv_betas, axis=0)\n",
    "mm_est_mean_r2 = np.mean(mm_est_cv_r2_scores)\n",
    "mm_est_std_r2 = np.std(mm_est_cv_r2_scores)\n",
    "\n",
    "print(\"\\nOverall Results [MM-Estimation with Tukey's Biweight]:\")\n",
    "print(f\"Mean R-squared: {mm_est_mean_r2:.4f} (±{mm_est_std_r2:.4f})\")\n",
    "print(\"\\nMean Beta Coefficients:\")\n",
    "feature_names = ['Intercept'] + list(data.columns[1:-1])\n",
    "for name, beta_mean, beta_std in zip(feature_names, mm_est_mean_beta, mm_est_std_beta):\n",
    "    print(f\"{name}: {beta_mean:.4f} (±{beta_std:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
