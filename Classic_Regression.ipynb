{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.optimize import minimize\n",
    "np.set_printoptions(precision=8, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinary Least Squares (Using Cross Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/91959/Desktop/CODE'\n",
    "                '/Robust-Penalized-Empirical-Likelihood-Estimation-Method-for-Linear-Regression/Data/Alcohol.csv')\n",
    "\n",
    "# Independent variables (features) - all columns except the first (Alcohol) and last (ln (Sol)exp)\n",
    "X = data.iloc[:, 1:-1].values  # Exclude the first column (Alcohol) and the last column (ln (Sol)exp)\n",
    "# Dependent variable (target) - last column (ln (Sol)exp)\n",
    "y = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up k-fold cross-validation\n",
    "k = 5  # number of folds\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store results OLS\n",
    "ols_cv_betas = []\n",
    "ols_cv_r2_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X), 1):\n",
    "    # Split data for this fold\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Add bias term to training data\n",
    "    X_train_bias = np.column_stack((np.ones(X_train.shape[0]), X_train))\n",
    "\n",
    "    # Calculate beta using normal equation\n",
    "    XT = X_train_bias.T\n",
    "    XT_X = np.dot(XT, X_train_bias)\n",
    "    XT_X_inv = np.linalg.inv(XT_X)\n",
    "    XT_y = np.dot(XT, y_train)\n",
    "    beta = np.dot(XT_X_inv, XT_y)\n",
    "\n",
    "    # Add bias term to test data\n",
    "    X_test_bias = np.column_stack((np.ones(X_test.shape[0]), X_test))\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = np.dot(X_test_bias, beta)\n",
    "\n",
    "    # Calculate R-squared\n",
    "    y_test_mean = np.mean(y_test)\n",
    "    SS_res = np.sum((y_test - y_pred) ** 2)\n",
    "    SS_tot = np.sum((y_test - y_test_mean) ** 2)\n",
    "    r2 = 1 - (SS_res / SS_tot)\n",
    "\n",
    "    # Store results\n",
    "    ols_cv_betas.append(beta)\n",
    "    ols_cv_r2_scores.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Results [OLS]:\n",
      "Mean R-squared: 0.9275 (±0.0373)\n",
      "\n",
      "Mean Beta Coefficients:\n",
      "Intercept: 29.1271 (±25.9525)\n",
      "SAG: -0.0047 (±0.0596)\n",
      "V: -0.0164 (±0.0542)\n",
      "Log P: -2.4590 (±0.7336)\n",
      "P: 27.1147 (±26.0920)\n",
      "RM: -1.0957 (±1.3066)\n",
      "Mass: -3.1410 (±3.5617)\n"
     ]
    }
   ],
   "source": [
    "# Calculate overall mean and standard deviation of results\n",
    "ols_mean_beta = np.mean(ols_cv_betas, axis=0)\n",
    "ols_std_beta = np.std(ols_cv_betas, axis=0)\n",
    "ols_mean_r2 = np.mean(ols_cv_r2_scores)\n",
    "ols_std_r2 = np.std(ols_cv_r2_scores)\n",
    "\n",
    "print(\"\\nOverall Results [OLS]:\")\n",
    "print(f\"Mean R-squared: {ols_mean_r2:.4f} (±{ols_std_r2:.4f})\")\n",
    "print(\"\\nMean Beta Coefficients:\")\n",
    "feature_names = ['Intercept'] + list(data.columns[1:-1])\n",
    "for name, beta_mean, beta_std in zip(feature_names, ols_mean_beta, ols_std_beta):\n",
    "    print(f\"{name}: {beta_mean:.4f} (±{beta_std:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intercept: 29.1271 (±25.9525) - This wide range suggests the OLS model is not very stable across different subsets of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Likelihood Estimation (Using Cross Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up k-fold cross-validation\n",
    "k = 5  # number of folds\n",
    "kf2 = KFold(n_splits=k, shuffle=True, random_state=44)\n",
    "\n",
    "# Lists to store results MLE\n",
    "mle_cv_betas = []\n",
    "mle_cv_r2_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(kf2.split(X), 1):\n",
    "    # Split data for this fold\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Add bias term to training data\n",
    "    X_train_bias = np.column_stack((np.ones(X_train.shape[0]), X_train))\n",
    "\n",
    "    # Get initial guess using OLS\n",
    "    ols_beta = np.linalg.inv(X_train_bias.T @ X_train_bias) @ X_train_bias.T @ y_train\n",
    "    initial_sigma = np.std(y_train - X_train_bias @ ols_beta)\n",
    "    initial_params = np.concatenate([ols_beta, [np.log(initial_sigma)]])\n",
    "\n",
    "    # Define the objective function (negative log likelihood)\n",
    "    def objective(params):\n",
    "        beta = params[:-1]\n",
    "        sigma = np.exp(params[-1])\n",
    "        y_pred = X_train_bias @ beta\n",
    "        n = len(y_train)\n",
    "        return n/2 * np.log(2 * np.pi) + n * np.log(sigma) + np.sum((y_train - y_pred)**2) / (2 * sigma**2)\n",
    "\n",
    "    # Minimize negative log likelihood\n",
    "    result = minimize(objective, initial_params, method='BFGS')\n",
    "\n",
    "    # Extract parameters\n",
    "    beta = result.x[:-1]\n",
    "    sigma = np.exp(result.x[-1])\n",
    "\n",
    "    # Add bias term to test data\n",
    "    X_test_bias = np.column_stack((np.ones(X_test.shape[0]), X_test))\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = X_test_bias @ beta\n",
    "\n",
    "    # Calculate R-squared\n",
    "    y_test_mean = np.mean(y_test)\n",
    "    SS_res = np.sum((y_test - y_pred) ** 2)\n",
    "    SS_tot = np.sum((y_test - y_test_mean) ** 2)\n",
    "    r2 = 1 - (SS_res / SS_tot)\n",
    "\n",
    "    # Store results\n",
    "    mle_cv_betas.append(beta)\n",
    "    mle_cv_r2_scores.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Results [MLE]:\n",
      "Mean R-squared: 0.8417 (±0.2565)\n",
      "\n",
      "Mean Beta Coefficients:\n",
      "Intercept: 29.8309 (±25.2362)\n",
      "SAG: 0.0162 (±0.0248)\n",
      "V: -0.0307 (±0.0209)\n",
      "Log P: -2.6767 (±0.8164)\n",
      "P: 29.6235 (±21.0984)\n",
      "RM: -1.3026 (±1.6532)\n",
      "Mass: -3.3857 (±3.2111)\n"
     ]
    }
   ],
   "source": [
    "# Calculate overall mean and standard deviation of results\n",
    "mle_mean_beta = np.mean(mle_cv_betas, axis=0)\n",
    "mle_std_beta = np.std(mle_cv_betas, axis=0)\n",
    "mle_mean_r2 = np.mean(mle_cv_r2_scores)\n",
    "mle_std_r2 = np.std(mle_cv_r2_scores)\n",
    "\n",
    "print(\"\\nOverall Results [MLE]:\")\n",
    "print(f\"Mean R-squared: {mle_mean_r2:.4f} (±{mle_std_r2:.4f})\")\n",
    "print(\"\\nMean Beta Coefficients:\")\n",
    "feature_names = ['Intercept'] + list(data.columns[1:-1])\n",
    "for name, beta_mean, beta_std in zip(feature_names, mle_mean_beta, mle_std_beta):\n",
    "    print(f\"{name}: {beta_mean:.4f} (±{beta_std:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
